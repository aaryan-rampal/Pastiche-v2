{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "6c60983f-ea66-4bc4-a489-ef953fcab557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2, numpy, vptree, PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import faiss\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "420573f3-199b-4dc9-8f58-ba79548b2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img):\n",
    "    if (len(img.shape) == 2):\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(img, interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "eb2a34c1-f0a4-46c1-b49c-e52a8f004926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_many(images):\n",
    "    num_images = len(images)\n",
    "    \n",
    "    # Create a figure and axis objects\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(12, 4))\n",
    "    \n",
    "    # Plot each image\n",
    "    for i, image in enumerate(images):\n",
    "        axes[i].imshow(image, cmap='gray')\n",
    "        axes[i].set_title(f'Image {i+1}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c755e3ce-26f2-451f-bf03-00017eb6f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns image into the shape (x, x, 3)\n",
    "def reorient_channels(img):\n",
    "    if len(img.shape) == 2:\n",
    "        return img\n",
    "    if len(img.shape) != 3:\n",
    "        raise Exception(\"Image does not have 2 or 3 channels\")\n",
    "\n",
    "    # color_channel = img.shape.index(3)\n",
    "    channels = [-1, -1, -1]\n",
    "    shape = img.shape\n",
    "    for i in range(3):\n",
    "        if shape[i] == 3:\n",
    "            channels[2] = i\n",
    "        else:\n",
    "            idx = channels.index(-1)\n",
    "            channels[idx] = i\n",
    "            \n",
    "    # print(channels)\n",
    "    correct = tf.transpose(img, [channels[0], channels[1], channels[2]])\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "c29387da-574f-4036-afb9-455aa60ee000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_detection(image, val):\n",
    "    # Apply Gaussian blur\n",
    "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    \n",
    "    # Convert to np.uint8\n",
    "    blurred_image_uint8 = np.uint8(blurred_image * 255)\n",
    "    \n",
    "    # Perform Canny edge detection\n",
    "    edges = cv2.Canny(blurred_image_uint8, val, val * 2)\n",
    "    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "3b8de499-4153-41c6-bf9b-9181d31052d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def canny(img, thresh1, thresh2):\n",
    "#     img_uint8 = (img.numpy() * 255).astype(np.uint8)\n",
    "#     return cv2.Canny(img_uint8, thresh1, thresh2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "501101c9-89c2-493d-ab30-040bea7b82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = torch.load('edges.pt')\n",
    "og = torch.load('og.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "09109955-a201-4abb-9d15-ebb3902250cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_edges = []\n",
    "\n",
    "for i in range(len(edges)):\n",
    "    val = 50\n",
    "    scaled = (edges[i].numpy() * 255).astype('uint8')\n",
    "    canny = canny_edge_detection(reorient_channels(og[i]).numpy(), 100)\n",
    "    canny_edges.append(canny)\n",
    "    # plot_many([edges[i], cv2.Canny(scaled, val, 2 * val), reorient_channels(og[i]), canny_edge_detection(reorient_channels(og[i]).numpy(), 100), canny])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "ba4bc40b-86ad-454c-bbe4-8f0f492a7e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 <class 'list'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(len(canny_edges), type(canny_edges), type(canny_edges[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "6d213cf3-2dfc-43aa-a882-f214562e34c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor_list = []\n",
    "\n",
    "for i in range(len(canny_edges)):\n",
    "    contours, hierarchy = cv2.findContours(canny_edges[i], cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contour_list = []\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 35 and cv2.arcLength(contour,-1) > 100:\n",
    "            contour_list.append(contour)\n",
    "        \n",
    "    for idx,item in enumerate(contour_list):\n",
    "        points_tensor = torch.from_numpy(contour_list[idx][:,0,:])\n",
    "        centroid = points_tensor.float().mean(dim=0)\n",
    "        centered_points = (points_tensor - centroid).to(torch.float64)\n",
    "        cnt1 = centered_points.numpy()\n",
    "        scale = np.max(np.abs(cnt1))\n",
    "        # print(scale)\n",
    "        cnt1 /= scale\n",
    "        dft = np.fft.fft(cnt1[:, 0] + 1j * cnt1[:, 1])\n",
    "        descriptors = dft[:10]\n",
    "        real_vectors = np.concatenate((np.real(descriptors), np.imag(descriptors)), axis=0)\n",
    "        descriptor_list.append(real_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "5d96ea11-8cde-4f08-8933-e7815e3f3b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(np.array(descriptor_list))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a5b83e8b-096b-4e83-ac5d-2675a253789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, contour in enumerate(contours):\n",
    "#     contour_shape = contours[0].shape\n",
    "#     # \n",
    "#     # Create a zero array with the same shape as contours[0], plus an additional dimension\n",
    "#     contour_image = np.zeros((1,) + contour_shape, dtype=np.uint8)\n",
    "\n",
    "#     # Draw the current contour on the blank image\n",
    "#     cv2.drawContours(contour_image, [contour], -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "#     # Save the contour image to a separate file\n",
    "#     contour_filename = os.path.join(output_dir, f'contour_{i}.jpg')\n",
    "#     cv2.imwrite(contour_filename, contour_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a84a9fd2-7007-4d1e-be7f-807368e6e887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "6c6dd2d7-523d-4000-8051-999501afbd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_img = np.zeros((128, 128, 3), dtype=np.uint8)\n",
    "\n",
    "# # cv2.drawContours(source_img, contour_list, 3, (0,255,0), 1)\n",
    "\n",
    "# for idx, item in enumerate(contours):\n",
    "#     source_img = np.zeros((128, 128, 3), dtype=np.uint8)\n",
    "#     filename = os.path.join(output_dir, f\"array_{idx}.jpg\")\n",
    "#     cv2.imwrite(filename, cv2.drawContours(source_img, contours, idx, (0,255,0), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "5cdc376c-3cde-4e64-9a09-6fc1f645d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Create an empty tensor to store the binary masks\n",
    "# tensor_list = []\n",
    "\n",
    "# for idx, item in enumerate(contours):\n",
    "#     # Create a tensor of zeros with shape (128, 128)\n",
    "#     tensor = torch.zeros(128, 128)\n",
    "    \n",
    "#     # Set the specified indices to 1\n",
    "#     for point in item:\n",
    "#         y, x = point[0]  # Extract y and x coordinates\n",
    "#         tensor[x, y] = 1  # Set the value at the specified indices to 1\n",
    "    \n",
    "#     # Append the tensor to the tensor list\n",
    "#     tensor_list.append(tensor)\n",
    "\n",
    "# # Stack the tensors along a new dimension to create the ultimate tensor\n",
    "# ultimate_tensor = torch.stack(tensor_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "66baa3c3-baa1-413c-b2e8-93fa2bc4d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist = 15\n",
    "k = 4\n",
    "d = a.shape[1]\n",
    "quantizer = faiss.IndexFlatL2(d)  # the other index\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
    "assert not index.is_trained\n",
    "index.train(a)\n",
    "assert index.is_trained\n",
    "\n",
    "index.add(a)                     # add may be a bit slower as well\n",
    "# D, I = index.search(xq, k)     # actual search\n",
    "# print(I[-5:])                  # neighbors of the 5 last queries\n",
    "# index.nprobe = 10              # default nprobe is 1, try a few more\n",
    "# D, I = index.search(xq, k)\n",
    "# print(I[-5:])                  # neighbors of the 5 last queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "d8be4632-eb1b-43a7-965a-745ce3c2bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_bytes = faiss.serialize_index(index)\n",
    "with open('index.pickle', 'wb') as f:\n",
    "    pickle.dump(index_bytes, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
