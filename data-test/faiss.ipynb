{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "6c60983f-ea66-4bc4-a489-ef953fcab557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2, numpy, vptree, PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import faiss\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "420573f3-199b-4dc9-8f58-ba79548b2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img):\n",
    "    if (len(img.shape) == 2):\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(img, interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "eb2a34c1-f0a4-46c1-b49c-e52a8f004926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_many(images):\n",
    "    num_images = len(images)\n",
    "    \n",
    "    # Create a figure and axis objects\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(12, 4))\n",
    "    \n",
    "    # Plot each image\n",
    "    for i, image in enumerate(images):\n",
    "        axes[i].imshow(image, cmap='gray')\n",
    "        axes[i].set_title(f'Image {i+1}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c755e3ce-26f2-451f-bf03-00017eb6f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns image into the shape (x, x, 3)\n",
    "def reorient_channels(img):\n",
    "    if len(img.shape) == 2:\n",
    "        return img\n",
    "    if len(img.shape) != 3:\n",
    "        raise Exception(\"Image does not have 2 or 3 channels\")\n",
    "\n",
    "    # color_channel = img.shape.index(3)\n",
    "    channels = [-1, -1, -1]\n",
    "    shape = img.shape\n",
    "    for i in range(3):\n",
    "        if shape[i] == 3:\n",
    "            channels[2] = i\n",
    "        else:\n",
    "            idx = channels.index(-1)\n",
    "            channels[idx] = i\n",
    "            \n",
    "    # print(channels)\n",
    "    correct = tf.transpose(img, [channels[0], channels[1], channels[2]])\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "c29387da-574f-4036-afb9-455aa60ee000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_detection(image, val):\n",
    "    # Apply Gaussian blur\n",
    "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    \n",
    "    # Convert to np.uint8\n",
    "    blurred_image_uint8 = np.uint8(blurred_image * 255)\n",
    "    \n",
    "    # Perform Canny edge detection\n",
    "    edges = cv2.Canny(blurred_image_uint8, val, val * 2)\n",
    "    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "3b8de499-4153-41c6-bf9b-9181d31052d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def canny(img, thresh1, thresh2):\n",
    "#     img_uint8 = (img.numpy() * 255).astype(np.uint8)\n",
    "#     return cv2.Canny(img_uint8, thresh1, thresh2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "501101c9-89c2-493d-ab30-040bea7b82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = torch.load('edges.pt')\n",
    "og = torch.load('og.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "09109955-a201-4abb-9d15-ebb3902250cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_edges = []\n",
    "\n",
    "for i in range(len(edges)):\n",
    "    val = 50\n",
    "    scaled = (edges[i].numpy() * 255).astype('uint8')\n",
    "    canny = canny_edge_detection(reorient_channels(og[i]).numpy(), 100)\n",
    "    canny_edges.append(canny)\n",
    "    # plot_many([edges[i], cv2.Canny(scaled, val, 2 * val), reorient_channels(og[i]), canny_edge_detection(reorient_channels(og[i]).numpy(), 100), canny])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "ba4bc40b-86ad-454c-bbe4-8f0f492a7e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 <class 'list'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(len(canny_edges), type(canny_edges), type(canny_edges[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "6d213cf3-2dfc-43aa-a882-f214562e34c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor_list = []\n",
    "\n",
    "contour_list = []\n",
    "\n",
    "for i in range(len(canny_edges)):\n",
    "    contours, hierarchy = cv2.findContours(canny_edges[i], cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 35 and cv2.arcLength(contour,-1) > 100:\n",
    "            contour_list.append(contour)\n",
    "        \n",
    "    for idx,item in enumerate(contour_list):\n",
    "        points_tensor = torch.from_numpy(contour_list[idx][:,0,:])\n",
    "        centroid = points_tensor.float().mean(dim=0)\n",
    "        centered_points = (points_tensor - centroid).to(torch.float64)\n",
    "        cnt1 = centered_points.numpy()\n",
    "        scale = np.max(np.abs(cnt1))\n",
    "        # print(scale)\n",
    "        cnt1 /= scale\n",
    "        dft = np.fft.fft(cnt1[:, 0] + 1j * cnt1[:, 1])\n",
    "        descriptors = dft[:10]\n",
    "        real_vectors = np.concatenate((np.real(descriptors), np.imag(descriptors)), axis=0)\n",
    "        descriptor_list.append(real_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "5d96ea11-8cde-4f08-8933-e7815e3f3b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(np.array(descriptor_list))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a5b83e8b-096b-4e83-ac5d-2675a253789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, contour in enumerate(contours):\n",
    "#     contour_shape = contours[0].shape\n",
    "#     # \n",
    "#     # Create a zero array with the same shape as contours[0], plus an additional dimension\n",
    "#     contour_image = np.zeros((1,) + contour_shape, dtype=np.uint8)\n",
    "\n",
    "#     # Draw the current contour on the blank image\n",
    "#     cv2.drawContours(contour_image, [contour], -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "#     # Save the contour image to a separate file\n",
    "#     contour_filename = os.path.join(output_dir, f'contour_{i}.jpg')\n",
    "#     cv2.imwrite(contour_filename, contour_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a84a9fd2-7007-4d1e-be7f-807368e6e887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "6c6dd2d7-523d-4000-8051-999501afbd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_img = np.zeros((128, 128, 3), dtype=np.uint8)\n",
    "\n",
    "# # cv2.drawContours(source_img, contour_list, 3, (0,255,0), 1)\n",
    "\n",
    "# for idx, item in enumerate(contours):\n",
    "#     source_img = np.zeros((128, 128, 3), dtype=np.uint8)\n",
    "#     filename = os.path.join(output_dir, f\"array_{idx}.jpg\")\n",
    "#     cv2.imwrite(filename, cv2.drawContours(source_img, contours, idx, (0,255,0), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "5cdc376c-3cde-4e64-9a09-6fc1f645d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Create an empty tensor to store the binary masks\n",
    "# tensor_list = []\n",
    "\n",
    "# for idx, item in enumerate(contours):\n",
    "#     # Create a tensor of zeros with shape (128, 128)\n",
    "#     tensor = torch.zeros(128, 128)\n",
    "    \n",
    "#     # Set the specified indices to 1\n",
    "#     for point in item:\n",
    "#         y, x = point[0]  # Extract y and x coordinates\n",
    "#         tensor[x, y] = 1  # Set the value at the specified indices to 1\n",
    "    \n",
    "#     # Append the tensor to the tensor list\n",
    "#     tensor_list.append(tensor)\n",
    "\n",
    "# # Stack the tensors along a new dimension to create the ultimate tensor\n",
    "# ultimate_tensor = torch.stack(tensor_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "66baa3c3-baa1-413c-b2e8-93fa2bc4d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist = 15\n",
    "k = 4\n",
    "d = a.shape[1]\n",
    "quantizer = faiss.IndexFlatL2(d)  # the other index\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
    "assert not index.is_trained\n",
    "index.train(a)\n",
    "assert index.is_trained\n",
    "\n",
    "index.add(a)                     # add may be a bit slower as well\n",
    "# D, I = index.search(xq, k)     # actual search\n",
    "# print(I[-5:])                  # neighbors of the 5 last queries\n",
    "# index.nprobe = 10              # default nprobe is 1, try a few more\n",
    "# D, I = index.search(xq, k)\n",
    "# print(I[-5:])                  # neighbors of the 5 last queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "d8be4632-eb1b-43a7-965a-745ce3c2bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_bytes = faiss.serialize_index(index)\n",
    "with open('index.pickle', 'wb') as f:\n",
    "    pickle.dump(index_bytes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "6815748e-a8c9-427d-b24c-b6dc5b487bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "f1d3eb63-4b33-4684-8ce8-e24851965824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contour_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "267e1bdf-fd11-46f5-af28-21419a1e5bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.zeros((128, 128), dtype=np.uint8)\n",
    "for i in contour_list[100]:\n",
    "    coord = i[0]\n",
    "    image[coord[0], coord[1]] = 1\n",
    "    \n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ebd38a-2b59-4be4-9f07-b33eef106fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
