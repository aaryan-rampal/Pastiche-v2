{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b9172be-b765-417a-a14b-b42e5f23d89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaryan/miniconda3/lib/python3.11/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.9.0) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n",
      "2024-04-12 21:04:17.745265: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-12 21:04:18.771129: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import deeplake\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2, numpy, vptree, PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af32290-477f-4333-91fd-e34c4c54c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img):\n",
    "    if (len(img.shape) == 2):\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(img, interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bec677c-a966-4d38-8614-52a30c1adcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two(image1, image2):\n",
    "    # Create a figure and axis objects\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    \n",
    "    # Plot the first image on the left axis\n",
    "    axes[0].imshow(image1, cmap='gray')\n",
    "\n",
    "    axes[0].set_title('Image 1')\n",
    "    \n",
    "    # Plot the second image on the right axis\n",
    "    axes[1].imshow(image2, cmap='gray')\n",
    "    axes[1].set_title('Image 2')\n",
    "    \n",
    "    # Hide axis ticks and labels\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05377f22-92da-49e9-a6d2-8b70fb00a7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/wiki-art\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/wiki-art loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "ds = deeplake.load('hub://activeloop/wiki-art', 'eyJhbGciOiJub25lIiwidHlwIjoiSldUIn0.eyJpZCI6ImFhcnlhbnJhbXBhbCIsImFwaV9rZXkiOiJuYW10YWJ3WVVvWnFmWUNPb01nZmNQcDZZTXdqSTREWUNCTlY1dFBaRDNFb0wifQ.')\n",
    "labels_list = ds.labels.info['class_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb88843-84d6-4acd-9926-13617294f9c1",
   "metadata": {},
   "source": [
    "### Defines the transform for each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20c402d0-9dd1-42ef-a563-dc011ad77d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_expressionism',\n",
       " 'action_painting',\n",
       " 'analytical_cubism',\n",
       " 'art_nouveau_modern',\n",
       " 'baroque',\n",
       " 'color_field_painting',\n",
       " 'contemporary_realism',\n",
       " 'cubism',\n",
       " 'early_renaissance',\n",
       " 'expressionism',\n",
       " 'fauvism',\n",
       " 'high_renaissance',\n",
       " 'impressionism',\n",
       " 'mannerism_late_renaissance',\n",
       " 'minimalism',\n",
       " 'naive_art_primitivism',\n",
       " 'new_realism',\n",
       " 'northern_renaissance',\n",
       " 'pointillism',\n",
       " 'pop_art',\n",
       " 'post_impressionism',\n",
       " 'realism',\n",
       " 'rococo',\n",
       " 'romanticism',\n",
       " 'symbolism',\n",
       " 'synthetic_cubism',\n",
       " 'ukiyo_e']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02dc1a31-1bd0-476e-a811-24f356b8fc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = ['abstract_expressionism', 'action_painting', 'color_field_painting', 'impressionism', 'minimalism', 'pointillism', 'rococo', 'synthetic_cubism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fccf774d-e436-491a-a417-81066779f437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_expressionism',\n",
       " 'action_painting',\n",
       " 'color_field_painting',\n",
       " 'impressionism',\n",
       " 'minimalism',\n",
       " 'pointillism',\n",
       " 'rococo',\n",
       " 'synthetic_cubism']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8782e2ff-35f1-491a-99e4-4fd7b6ac0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@deeplake.compute\n",
    "def filter_labels(sample_in, labels_list):\n",
    "    return sample_in.labels.data()['text'] not in labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "07d9adff-0425-4a4c-896c-0d84110207c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 81433/81433 [00:02<00:00, 27545.43it/s]\n"
     ]
    }
   ],
   "source": [
    "filtered_ds = ds.filter(lambda sample_in: filter_labels(sample_in, filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6d684ff5-7689-46d0-bb3e-34aabd71d806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_expressionism',\n",
       " 'action_painting',\n",
       " 'analytical_cubism',\n",
       " 'art_nouveau_modern',\n",
       " 'baroque',\n",
       " 'color_field_painting',\n",
       " 'contemporary_realism',\n",
       " 'cubism',\n",
       " 'early_renaissance',\n",
       " 'expressionism',\n",
       " 'fauvism',\n",
       " 'high_renaissance',\n",
       " 'impressionism',\n",
       " 'mannerism_late_renaissance',\n",
       " 'minimalism',\n",
       " 'naive_art_primitivism',\n",
       " 'new_realism',\n",
       " 'northern_renaissance',\n",
       " 'pointillism',\n",
       " 'pop_art',\n",
       " 'post_impressionism',\n",
       " 'realism',\n",
       " 'rococo',\n",
       " 'romanticism',\n",
       " 'symbolism',\n",
       " 'synthetic_cubism',\n",
       " 'ukiyo_e']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_ds.labels.info['class_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1789e48-c6e8-4f17-9553-2e72c401ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "\n",
    "tform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize([img_size, img_size])\n",
    "    # transforms.Normalize([0,0,0], [255,255,255])\n",
    "])\n",
    "\n",
    "def transform(sample_in):\n",
    "    # sample_in['images'] is of type numpy.ndarray\n",
    "    return {'images': tform(sample_in['images']), 'labels': sample_in['labels']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57c30e4-1029-48da-a56a-f59278365953",
   "metadata": {},
   "source": [
    "Create the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da834763-87eb-454a-a018-714bce0b152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = ds.pytorch(num_workers=0, batch_size=64, shuffle=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a1ab85-c635-4764-bf2d-65a89865d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61920066-cbf6-47fb-8704-07c6bf5da23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(key='labels')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73c5e154-484e-4e91-8684-1bb4e068fae6",
   "metadata": {},
   "source": [
    "`process_batch_loop` does most of the transformations on numpy, but then loops through each numpy array (which is an img) and sends it to the edge detector.\n",
    "\n",
    "`process_batch` does all of the transformations on numpy. Then, it makes the `[x, 200, 200, 3]` numpy array into a `[200 * x, 200, 3]` numpy array, detects edges and splits it back into a `[x, 200, 200, 3]` numpy array\n",
    "\n",
    "`process_batch_t` does all of the transformations on tensors. Then, it makes the `[x, 200, 200, 3]` tensor into a numpy array before passing it into `detectEdges()` and splits it back into a `[x, 200, 200, 3]` tensor. It then adds all the tensors to `edge_list` and returns the list.\n",
    "\n",
    "`process_batch_t_stack` is the same as `process_batch_t` but it returns the `[x, 200, 200, 3]` tensor instead of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "657ac09a-bddf-4244-b3ae-4857e43859f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_string = \"\"\"\n",
    "# SELECT * \n",
    "# FROM ds \n",
    "# GROUP BY labels \n",
    "# LIMIT 5\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35ffaa52-5515-4311-b004-870045d62d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the destination path for the copied dataset\n",
    "# destination_path = \"test/\"\n",
    "\n",
    "# # Copy the dataset to the local destination\n",
    "# copied_ds = ds.copy(dest=destination_path)\n",
    "\n",
    "# # Define the query string to perform on the copied dataset\n",
    "# query_string = \"\"\"\n",
    "# SELECT * \n",
    "# FROM copied_ds \n",
    "# GROUP BY labels \n",
    "# LIMIT 5\n",
    "# \"\"\"\n",
    "\n",
    "# # Query the copied dataset\n",
    "# query_result_ds = copied_ds.query(query_string, runtime={'tensor_db': True}, return_data=True)\n",
    "\n",
    "# # Print some information about the query result\n",
    "# print(\"Number of samples in query result:\", len(query_result_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c44b5fa-2590-470a-b408-0ac488160223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(query_result_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e2c10ed-1b72-4465-9e50-0a4c8b6d4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch, edge_detector):\n",
    "    # print(type(batch))\n",
    "    batch_numpy = batch['images'].numpy()\n",
    "    # print(batch_numpy.shape)\n",
    "    \n",
    "    transposed_batch = np.transpose(batch_numpy, (0, 2, 3, 1))\n",
    "    # print(transposed_batch.shape)\n",
    "\n",
    "    \n",
    "    combined_image = np.concatenate(transposed_batch, axis=1)\n",
    "    # plot_image(combined_image)\n",
    "\n",
    "    # print(type(combined_image), combined_image.shape)\n",
    "\n",
    "    edges = edge_detector.detectEdges(combined_image)\n",
    "    # plot_image(edges)\n",
    "\n",
    "    return np.split(edges, len(batch['images']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48141df7-ba88-4356-a751-4499ac35da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_loop(batch, edge_detector):\n",
    "    batch_numpy = batch['images'].numpy()\n",
    "    transposed_batch = np.transpose(batch_numpy, (0, 2, 3, 1))\n",
    "    \n",
    "    edge_list = []\n",
    "    for img in transposed_batch:\n",
    "        edges = edge_detector.detectEdges(img)\n",
    "        edge_list.append(edges)\n",
    "\n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60ee7431-e39d-42b0-b217-5ed00b8f4027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_t(batch, edge_detector):\n",
    "    batch_numpy = batch['images']\n",
    "    # print(batch_numpy.shape)\n",
    "    \n",
    "    transposed_batch = tf.transpose(batch_numpy, (0, 2, 3, 1))\n",
    "    # print(transposed_batch.shape)\n",
    "    # print(len(batch['images']))\n",
    "    \n",
    "    combined_image = tf.reshape(transposed_batch, (img_size * len(batch['images']), img_size, 3)).numpy()\n",
    "    # print(type(combined_image), combined_image.shape)\n",
    "    # plot_image(combined_image)\n",
    "\n",
    "    edges = edge_detector.detectEdges(combined_image)\n",
    "    # plot_image(edges)\n",
    "\n",
    "    return tf.split(tf.convert_to_tensor(edges), len(batch['images']), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d54d912b-93d5-438c-ba40-67ea98190f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_t_stack(batch, edge_detector):\n",
    "    batch_numpy = batch['images']\n",
    "    # print(batch_numpy.shape)\n",
    "    \n",
    "    transposed_batch = tf.transpose(batch_numpy, (0, 2, 3, 1))\n",
    "    # print(transposed_batch.shape)\n",
    "    # print(len(batch['images']))\n",
    "    \n",
    "    combined_image = tf.reshape(transposed_batch, (img_size * len(batch['images']), img_size, 3)).numpy()\n",
    "    # print(type(combined_image), combined_image.shape)\n",
    "    # plot_image(combined_image)\n",
    "\n",
    "    edges = edge_detector.detectEdges(combined_image)\n",
    "\n",
    "    return tf.stack(tf.split(tf.convert_to_tensor(edges), len(batch['images']), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c42c597-f424-40f8-8213-f492925d9fce",
   "metadata": {},
   "source": [
    "### Iterating over the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0846886-68f6-4209-b324-81b93c3e96f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_detector = cv2.ximgproc.createStructuredEdgeDetection('model.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b49e56d-fd24-4ba4-931e-a781d4bd31c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 20:33:00.580318: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 20:33:00.581474: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 20:33:00.581613: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 20:33:00.582733: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 20:33:00.582880: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 20:33:00.583016: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 20:33:00.646025: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 20:33:00.646182: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 20:33:00.646293: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-10 20:33:00.646381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 584 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "edge_tensor = None\n",
    "i = 0\n",
    "og_list = []\n",
    "\n",
    "start_time_1 = time.time()\n",
    "for batch in iter(dataloader):\n",
    "    og_list.extend(batch['images'])\n",
    "\n",
    "    obj = process_batch_t_stack(batch, edge_detector)\n",
    "    \n",
    "    if edge_tensor is None:\n",
    "        edge_tensor = obj\n",
    "    else:\n",
    "        edge_tensor = tf.concat([edge_tensor, obj], axis = 0)\n",
    "    i += 1\n",
    "    if (i == 5):\n",
    "        end_time_1 = time.time()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89d123ff-7ec0-4662-bbd0-1fc2434f7a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3083808628939888\n"
     ]
    }
   ],
   "source": [
    "# print(times)\n",
    "print(edge_tensor.shape[0] / (end_time_1 - start_time_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f729b8-8608-494a-b367-5587d00ced56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for tens in edge_tensor:\n",
    "#     # print(tens.shape)\n",
    "#     # print(og_list[i].shape)\n",
    "#     plot_two(tens.numpy(), tf.transpose(og_list[i], [1, 2, 0]).numpy())\n",
    "#     # plot_image(tens.numpy())\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "444f4bfb-7645-4f85-b688-07cda4c22f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(og_list))\n",
    "og_tensor = tf.stack(og_list)\n",
    "# print(og_tensor.shape)\n",
    "# print(og_tensor.shape)\n",
    "# print(edge_tensor.shape)\n",
    "torch.save(edge_tensor, 'edges.pt')\n",
    "torch.save(og_tensor, 'og.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e530656-4867-49db-a1a2-0ee32e104121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(edge_tensor)):\n",
    "#     plot_two(edge_tensor[i], tf.transpose(og_tensor[i], [1, 2, 0]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63ff3d07-909b-4b07-88b4-a0ffecba173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "saved_batch = torch.load('batch_data.pt')\n",
    "# print(time.time() - start)\n",
    "# saved_batch\n",
    "n = len(saved_batch['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a987a631-95b1-435b-900d-5f392aebc177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(saved_batch['images'])\n",
    "transposed = tf.transpose(saved_batch['images'], (0, 2, 3, 1))\n",
    "combined_image = tf.reshape(transposed, (200 * n, 200, 3)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "517f71eb-52a4-41ce-9e39-1cb6aafdbe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = edge_detector.detectEdges(combined_image)\n",
    "tens = tf.stack(tf.split(tf.convert_to_tensor(edges), n, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2623b41d-c6c2-4301-b5e6-d12b6447b778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "print(tens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc4023b-e926-4a2a-9ada-a577ca148d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tensor in tens:\n",
    "#     plot_image(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99f25b1c-c402-47d3-b002-b04f1b09dc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaryan/miniconda3/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 64: smart_tensor = 4.017817847992014 img/sec\n",
      "n = 128: smart_tensor = 19.789941884455615 img/sec\n",
      "n = 256: smart_tensor = 14.716899589092263 img/sec\n",
      "n = 512: smart_tensor = 17.756189379732167 img/sec\n"
     ]
    }
   ],
   "source": [
    "edge_detector = cv2.ximgproc.createStructuredEdgeDetection('model.yml')\n",
    "\n",
    "for siz in range(6, 10):\n",
    "    dataloader = ds.pytorch(num_workers=2, batch_size=2 ** siz, shuffle=False, transform=transform)\n",
    "    # edge_list_1 = []\n",
    "    # i = 0\n",
    "    # start_time_1 = time.time()\n",
    "    # for batch in iter(dataloader):\n",
    "    #     edge_list_1.extend(process_batch(batch, edge_detector))\n",
    "    #     i += 1\n",
    "    #     if (i == 10):\n",
    "    #         end_time_1 = time.time()\n",
    "    #         break\n",
    "            \n",
    "    # edge_list_2 = []\n",
    "    # i = 0\n",
    "    # start_time_2 = time.time()\n",
    "    # for batch in iter(dataloader):\n",
    "    #     edge_list_2.extend(process_batch_loop(batch, edge_detector))\n",
    "    #     i += 1\n",
    "    #     if (i == 10):\n",
    "    #         end_time_2 = time.time()\n",
    "    #         break\n",
    "\n",
    "    edge_list_3 = []\n",
    "    i = 0\n",
    "    start_time_3 = time.time()\n",
    "    for batch in iter(dataloader):\n",
    "        edge_list_3.extend(process_batch_t(batch, edge_detector))\n",
    "        i += 1\n",
    "        if (i == 5):\n",
    "            end_time_3 = time.time()\n",
    "            break\n",
    "\n",
    "    # print(f\"n = {siz}: naive = {len(edge_list_2)/(end_time_2 - start_time_2)} img/sec, smart = {len(edge_list_1)/(end_time_1 - start_time_1)} img/sec, smart_tensor = {len(edge_list_3)/(end_time_3 - start_time_3)} img/sec\")\n",
    "    print(f\"n = {2 ** siz}: smart_tensor = {len(edge_list_3)/(end_time_3 - start_time_3)} img/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fefff417-281f-49d2-aa75-d2013bf58d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(482, 604, 3)\n"
     ]
    }
   ],
   "source": [
    "im1 = ds.images[27272].numpy() # Fetch the first image and return a numpy array\n",
    "print(im1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f8e58ba-078e-47cf-89ed-2ab0de7a4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "# image = image.astype(np.float32) / 255.0\n",
    "# plot_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22fd8f9d-0999-4ee1-8e3c-58a8da632e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(533, 600, 3)\n"
     ]
    }
   ],
   "source": [
    "triangle = cv2.imread('triangle.jpg')\n",
    "# triangle = cv2.cvtColor(triangle, cv2.COLOR_GRAY2BGR)\n",
    "triangle_color = cv2.merge([triangle])\n",
    "triangle = triangle_color.astype(np.float32) / 255.0\n",
    "# plot_image(triangle)\n",
    "print(triangle.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d0709-7717-4b7f-9bd2-da7a9d057611",
   "metadata": {},
   "source": [
    "`Canny()` requires a grayscale image. It is also very senstitive to outliers so you add a blur function to remove some of the outliers. The blurring is not necessary but helps to reduce unnecessary edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d43026dd-4ced-48fe-a85f-8a44e4a4f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edges = cv2.Canny(blurred,100,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "393fe865-cf09-4474-a2a4-801fc24f4069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot_image(gray)\n",
    "# # plot_image(blurred)\n",
    "# plot_image(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b5abe8-5e1d-49e4-892a-995a2512b366",
   "metadata": {},
   "source": [
    "`detectEdges()` requires a color image, and it wants each value of the array to be a float between 0 and 1. Therefore, you convert it to a float, and divide it by 255 (the maximum value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52854e20-a40c-4e42-a25c-161e3973a260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(482, 604, 3)\n"
     ]
    }
   ],
   "source": [
    "image = im1.astype(np.float32) / 255.0\n",
    "# print(image[0])\n",
    "print(image.shape)\n",
    "# detectEdges requires a color image\n",
    "# print(image)\n",
    "\n",
    "edges = edge_detector.detectEdges(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41076100-5ba0-46b1-a7a1-d2c534945c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_image(edges)\n",
    "# print(edges.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea128e32-1c1a-455d-a057-02b5760a3922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.00048828 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.00146484 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False  True ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n"
     ]
    }
   ],
   "source": [
    "print(edges)\n",
    "print(edges > 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0587d658-3074-40f1-ae38-db14c1b24baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /io/opencv/modules/imgproc/src/canny.cpp:829: error: (-215:Assertion failed) _src.depth() == CV_8U in function 'Canny'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m edges[\u001b[38;5;241m~\u001b[39mmask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(edges)\n\u001b[0;32m----> 7\u001b[0m cann \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCanny\u001b[49m\u001b[43m(\u001b[49m\u001b[43medges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /io/opencv/modules/imgproc/src/canny.cpp:829: error: (-215:Assertion failed) _src.depth() == CV_8U in function 'Canny'\n"
     ]
    }
   ],
   "source": [
    "mask = edges > 0.001\n",
    "\n",
    "edges[mask] = 1\n",
    "edges[~mask] = 0\n",
    "\n",
    "print(edges)\n",
    "cann = cv2.Canny(edges, 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac770da-089e-4817-8484-73610404fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_trng = edge_detector.detectEdges(triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2bebec-44fb-435e-9ab9-b5bdcb9fa63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(edges_trng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadf0a46-c4ed-4225-8a41-9bc7c409c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688073dc-9f59-49fa-a027-3b7f8ca9e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(d)   # build the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f685acf-b575-4d67-aa15-bcfd402d7e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 64                           # dimension\n",
    "nb = 100000                      # database size\n",
    "nq = 10000                       # nb of queries\n",
    "np.random.seed(1234)             # make reproducible\n",
    "xb = np.random.random((nb, d)).astype('float32')\n",
    "xb[:, 0] += np.arange(nb) / 1000.\n",
    "xq = np.random.random((nq, d)).astype('float32')\n",
    "xq[:, 0] += np.arange(nq) / 1000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaab57ec-51b4-4fc3-a807-d54fc893da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e0baa5-5fe0-4d9f-822b-e5c4fab6d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(edge_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc0d51-4a9c-430d-bfcf-f7fa33e9f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edge_tensor[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa8aae-10a4-444b-a341-6bb9f8d5532a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
